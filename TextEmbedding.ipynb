{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOAuEMxlKPQq+btUUAby4e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/ChatGPTHackathon/blob/main/TextEmbedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cYx8CVBm5pUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ðŸš€ ðŸŒ Get Ready for the DIA Hackathon Extravaganza! ðŸŒ ðŸš€\n",
        "\n",
        "Hello, innovative minds of the DIA unit! ðŸ§ \n",
        "\n",
        "We are excited to share this Jupyter Notebook, designed as a starting point for our epic journey at the DIA Hackathon on May 12th, 2023. This notebook will help you dive into the world of text embeddings using OpenAI's GPT-4 model, providing you with the foundation for the project.\n",
        "\n",
        "ðŸŽ¯ Our Mission: Use the awe-inspiring power of ChatGPT to streamline Clinnova's study protocol and data protection notice, enabling seamless Q&A sessions for study participants.\n",
        "\n",
        "The notebook demonstrates how to:\n",
        "\n",
        "Install required packages\n",
        "Mount Google Drive and import necessary modules\n",
        "Load Clinnova's text from a file\n",
        "Define and use the get_embedding function to obtain text embeddings from OpenAI API\n",
        "With this foundation, you'll be well-equipped to tackle the challenges ahead, working with string embeddings and vector databases, and using the mighty OpenAI API services to revolutionize the world of clinical studies.\n",
        "\n",
        "Get ready to network with the brightest minds, enjoy delicious snacks and drinks, and be part of a groundbreaking project! ðŸŽ‰\n",
        "\n",
        "We can't wait to see you on May 12th, 2023, and witness the incredible solutions you'll create!\n",
        "\n",
        "Best regards,\n",
        "\n",
        "The DIA Hackathon Team"
      ],
      "metadata": {
        "id": "BmRB9a1Q6EWO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAKpyVTrvHJY"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade openai\n",
        "%pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/your_folder') #change\n",
        "from APIkey import API_key\n",
        "\n",
        "import openai\n",
        "import tiktoken\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sAYFCipuvyyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/your_folder/ClinnovaDocs.txt') as f: #change\n",
        "    ClinnovaText = f.read()"
      ],
      "metadata": {
        "id": "CO5O5GdfvXWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = API_key"
      ],
      "metadata": {
        "id": "D7Ce-0FewhFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_embedding(text: str, model=\"text-embedding-ada-002\") -> list[float]:\n",
        "    return openai.Embedding.create(input=[text], model=model)[\"data\"][0][\"embedding\"]"
      ],
      "metadata": {
        "id": "tOEfOQxGwsNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = get_embedding(\"Hello World\", model=\"text-embedding-ada-002\")\n",
        "print(len(embedding))"
      ],
      "metadata": {
        "id": "iehnxWkWw0oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#More Information\n",
        "[Embedding of long text](https://github.com/openai/openai-cookbook/blob/main/examples/Embedding_long_inputs.ipynb)\n",
        "\n",
        "This Jupyter notebook demonstrates how to handle texts that are longer than a model's maximum context length when using OpenAI's embedding models, such as text-embedding-ada-002. The maximum context length is measured by tokens, and exceeding this limit causes an error. The notebook covers two main approaches to handle longer texts: truncation and chunking.\n",
        "\n",
        "Truncation: The input text is truncated to the maximum allowed length. The notebook provides a function, truncate_text_tokens, that takes care of the tokenization and truncation process.\n",
        "\n",
        "Chunking: The input text is divided into chunks and each chunk is embedded individually. The notebook provides a function, len_safe_get_embedding, which handles chunking and embedding. The embeddings can be returned as a weighted average or as a list of individual chunk embeddings.\n",
        "\n",
        "The notebook also includes utility functions like batched, chunked_tokens, and len_safe_get_embedding to facilitate the process of handling longer texts."
      ],
      "metadata": {
        "id": "U1fq6O4c5MGG"
      }
    }
  ]
}